{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQsbnj2VLECP"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u-LB_cpLwV7"
      },
      "source": [
        "# **Importing the DataSet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeuDgFONL7vI"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, GRU, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePOkN78-LwEq"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset from Hugging Face\n",
        "dataset = load_dataset(\"tanzuhuggingface/creditcardfraudtraining\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRTwImWEOJUV"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF6OyaqPOh_W"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "df.head()  # This helps in understanding the structure and sample data of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zg-d8D4Ou_m"
      },
      "outputs": [],
      "source": [
        "# Display summary information about the DataFrame\n",
        "df.info()  # Provides an overview of the dataset, including column names, data types, and non-null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps3WHIwRPAxh"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of each unique value in the \"is_fraud\" column\n",
        "df[\"is_fraud\"].value_counts()  # Helps in understanding the class distribution (fraud vs. non-fraud cases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVqflGQ6PM6T"
      },
      "outputs": [],
      "source": [
        "#Checking for missing values in the dataset\n",
        "df.isnull().sum()  # Displays the count of missing values for each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3A5Bt09Pnfs"
      },
      "outputs": [],
      "source": [
        "# Display basic statistical summary of the dataset\n",
        "\n",
        "df.describe()  # Provides statistics like mean, standard deviation, min, max, and quartiles for numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDcvHj3lP5HZ"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of fraud and non-fraud cases\n",
        "fraud_percentage = df['is_fraud'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Display the class distribution in percentage\n",
        "fraud_percentage  # Helps in understanding class imbalance in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwhexrkTQeQZ"
      },
      "source": [
        "# **Drop the specified columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg9yJTD1Qa3w"
      },
      "outputs": [],
      "source": [
        "# Define the list of unnecessary columns to drop\n",
        "columns_to_drop = ['id', 'index']  # These columns may not contribute to model training or analysis\n",
        "\n",
        "# Drop the specified columns from the DataFrame\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Display confirmation message\n",
        "print(\"Columns dropped successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0hRZDbaQ7nD"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK7RjJmQRhOU"
      },
      "source": [
        "# **EDA (Exploratry Data Analysis)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gP36_KLRqpa"
      },
      "source": [
        "**Class Disstribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkbdM8TpReBy"
      },
      "outputs": [],
      "source": [
        "# Set figure size for better visualization\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "# Create a count plot for fraud vs. non-fraud distribution\n",
        "sns.countplot(data=df, x='is_fraud', palette=[\"#FF9999\", \"#66B2FF\"])  # Custom colors for better distinction\n",
        "\n",
        "# Add title and labels for better understanding\n",
        "plt.title(\"Class Distribution (Fraud vs. Non-Fraud)\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Fraud Status (0 = Non-Fraud, 1 = Fraud)\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "\n",
        "# Customize x-axis labels for clarity\n",
        "plt.xticks(ticks=[0, 1], labels=[\"Non-Fraud\", \"Fraud\"], fontsize=11)\n",
        "\n",
        "# Remove unnecessary legend to avoid redundancy\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dD2K05aSze4"
      },
      "outputs": [],
      "source": [
        "# Define figure size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Loop through all columns except \"is_fraud\"\n",
        "for column in df.columns:\n",
        "    if column != \"is_fraud\":\n",
        "        plt.figure(figsize=(6, 4))  # Set individual plot size\n",
        "\n",
        "        # Check if the column is categorical or numerical\n",
        "        if df[column].dtype == 'object' or df[column].nunique() < 10:  # Categorical or low-cardinality numeric\n",
        "            sns.countplot(data=df, x=column, hue=\"is_fraud\", palette=[\"#66B2FF\", \"#FF9999\"])\n",
        "        else:  # Numerical columns\n",
        "            sns.histplot(data=df, x=column, hue=\"is_fraud\", element=\"step\", palette=[\"#66B2FF\", \"#FF9999\"], bins=30, kde=True)\n",
        "\n",
        "        # Set titles and labels\n",
        "        plt.title(f\"Distribution of {column} by Fraud Status\", fontsize=12, fontweight='bold')\n",
        "        plt.xlabel(column, fontsize=11)\n",
        "        plt.ylabel(\"Count\", fontsize=11)\n",
        "        plt.legend(title=\"Fraud Status\", labels=[\"Non-Fraud\", \"Fraud\"])\n",
        "        plt.xticks(rotation=45)  # Rotate labels for better readability if necessary\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUXdk72FUWtO"
      },
      "outputs": [],
      "source": [
        "# Set figure size for better readability\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Create the heatmap with a different color scheme\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    cmap=\"viridis\",  # Changed color scheme to 'viridis' for better contrast\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    annot_kws={\"size\": 14, \"weight\": \"bold\"},  # Adjust font size and weight for annotations\n",
        "    linewidths=0.5,  # Add gridlines between cells for better separation\n",
        "    linecolor=\"white\",  # Grid color\n",
        "    cbar_kws={\"shrink\": 0.75}  # Adjust color bar size\n",
        ")\n",
        "\n",
        "# Set title and labels\n",
        "plt.title(\"Correlation Heatmap of Features\", fontsize=18, fontweight=\"bold\", color=\"#333333\")  # Darker title color\n",
        "plt.xticks(fontsize=14, fontweight='bold', rotation=45, color=\"#444444\")  # Rotate x-axis labels for clarity\n",
        "plt.yticks(fontsize=14, fontweight='bold', color=\"#444444\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r0KUZ74cEs0"
      },
      "outputs": [],
      "source": [
        "# Separating features (X) and target variable (y)\n",
        "X = df.drop(columns=['is_fraud'])  # Drop the target column to keep only predictor features\n",
        "y = df['is_fraud']  # Target variable containing fraud labels (0 = Non-Fraud, 1 = Fraud)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjDq-GewcPmG"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JdzhyAacXkE"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTS25kuqch2w"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}